{
  "hash": "b1fc865ee28160b818219c6dddce4f69",
  "result": {
    "markdown": "---\ntitle: Pokemon Classification Model\nexecute:\n  eval: false\n  warning: false\n  output: true\n  freeze: true\n---\n\n<h1> Pokemon Classification Model </h1>\n\n---\n\n<p> Let's start by importing the important stuff that we need. Next we download the data, build the data pipeline, train the model, and then hopefully deploy the model on my blog.</p>\n\n---\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom fastai.vision.all import *\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\nimport pandas as pd\npd.set_option('display.max_rows', 500)\nimport torch\ndevice = torch.device('mps')\n# torch.default_device(device)\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# download data from \ndef search_images(term, max_images=50): return L(ddg_images(term, max_results=max_images)).itemgot('image')\nurls = search_images('fire pokemon', max_images=10)\nurls[0]\n```\n:::\n\n\nNow let's build it to download a bunch of different Pokemon Types!\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport os\ndf = pd.read_csv('data/pokemon_df.csv')\ndf['Ndex'] = df['Ndex'].apply(lambda x: int(x[1:]))\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\npath_images = Path('data/pictures/pokemon_1.png')\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfor type in df['Type'].unique():\n    os.mkdir(f'data/pictures/{type}')\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Moving them in the correct folders\nfor i in range(1, len(df['Ndex'].unique())):\n    frame = df.loc[df['Ndex'] == i]\n    row = frame.iloc[0]\n    type = row['Type']\n    os.rename(f'data/pictures/pokemon_{i}.png', f'data/pictures/{type}/pokemon_{i}.png')\n```\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nget_image_files(path='data/pictures/')\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\npath = Path('data/pictures/')\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\npokemons = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# now we need to tell our datablock where our items are\ndls = pokemons.dataloaders(path)\n```\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndls.valid.show_batch(max_n=9, nrows=3)\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndefault_device()\n```\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Data Augmenation\n\n# This does not run on Mac M1 with MPS devices!\n\n# pokemons = pokemons.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\n# dls = pokemons.dataloaders(path)\n# dls.train.show_batch(max_n=8, nrows=2, unique=True)\n```\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Train and learning\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n```\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Exporting the weights\nlearn.path = Path('.')\nlearn.export()\n```\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# Let's see the big Matrix\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ninterp.plot_top_losses(5, nrows=1)\n```\n:::\n\n\nI mean these are tough. If I had never played pokemon before I could not predict what type they were.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n    \ndemo.launch()   \n```\n:::\n\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}