[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog. Here will Be my about page. Linking to Github and LinkedIn"
  },
  {
    "objectID": "posts/third_post/index.html",
    "href": "posts/third_post/index.html",
    "title": "This is a test post",
    "section": "",
    "text": "print('hello world')\n\nhello world\n\n\nThats it."
  },
  {
    "objectID": "posts/first_post/index.html",
    "href": "posts/first_post/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is my first post ever created. Welcome. This blog shall be a blog about recent projects and thoughts and whatever cool stuff I end up doing.\nFirst, I need to learn and understand how hosting a blog works. I use the Quarto blog. Quarto uses files such as Jupyter Notebooks to create a Webpage(who doesn’t love Jupyter notebooks). The cool thing about having Jupyter Notebooks is that we can put code executables on the blog such as this:\n\nprint('Hello World!')\n# What an icon first line for this blog\n\nHello World!\n\n\nWhen we have our blog post finished we can use commands such as: quarto render and then we add and commit our changes, and finally push to the repository. If we are hosting on a service such as Github Pages.\nWe can also display images.\n\n\n\nPikachu"
  },
  {
    "objectID": "posts/second_post/index.html",
    "href": "posts/second_post/index.html",
    "title": "Pokemon Classification Model",
    "section": "",
    "text": "Pokemon Classification Model\n\n\n\nLet’s start by importing the important stuff that we need. Next we download the data, build the data pipeline, train the model, and then hopefully deploy the model on my blog.\n\n\n\nfrom fastai.vision.all import *\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\nimport pandas as pd\npd.set_option('display.max_rows', 500)\nimport torch\ndevice = torch.device('mps')\n# torch.default_device(device)\n\n\n# download data from \ndef search_images(term, max_images=50): return L(ddg_images(term, max_results=max_images)).itemgot('image')\nurls = search_images('fire pokemon', max_images=10)\nurls[0]\n\nNow let’s build it to download a bunch of different Pokemon Types!\n\nimport os\ndf = pd.read_csv('data/pokemon_df.csv')\ndf['Ndex'] = df['Ndex'].apply(lambda x: int(x[1:]))\n\n\npath_images = Path('data/pictures/pokemon_1.png')\n\n\nfor type in df['Type'].unique():\n    os.mkdir(f'data/pictures/{type}')\n\n\n# Moving them in the correct folders\nfor i in range(1, len(df['Ndex'].unique())):\n    frame = df.loc[df['Ndex'] == i]\n    row = frame.iloc[0]\n    type = row['Type']\n    os.rename(f'data/pictures/pokemon_{i}.png', f'data/pictures/{type}/pokemon_{i}.png')\n\n\nget_image_files(path='data/pictures/')\n\n\npath = Path('data/pictures/')\n\n\npokemons = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\n\n# now we need to tell our datablock where our items are\ndls = pokemons.dataloaders(path)\n\n\ndls.valid.show_batch(max_n=9, nrows=3)\n\n\ndefault_device()\n\n\n# Data Augmenation\n\n# This does not run on Mac M1 with MPS devices!\n\n# pokemons = pokemons.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\n# dls = pokemons.dataloaders(path)\n# dls.train.show_batch(max_n=8, nrows=2, unique=True)\n\n\n# Train and learning\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n\n\n# Exporting the weights\nlearn.path = Path('.')\nlearn.export()\n\n\n# Let's see the big Matrix\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\ninterp.plot_top_losses(5, nrows=1)\n\nI mean these are tough. If I had never played pokemon before I could not predict what type they were.\n\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n    \ndemo.launch()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "Pokemon Classification Model\n\n\n\n\n\n\n\nfun\n\n\nfastai\n\n\n\n\n\n\n\n\n\n\n\nAug 23, 2023\n\n\nMyself\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nfun\n\n\n\n\n\n\n\n\n\n\n\nAug 20, 2023\n\n\nMyself\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/second_post/main.html",
    "href": "posts/second_post/main.html",
    "title": "Pokemon Classification Model",
    "section": "",
    "text": "Pokemon Classification Model\n\n\n\nLet’s start by importing the important stuff that we need. Next we download the data, build the data pipeline, train the model, and then hopefully deploy the model on my blog.\n\n\n\nfrom fastai.vision.all import *\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\nimport pandas as pd\nimport torch\nimport os\n\npd.set_option('display.max_rows', 500)\ndevice = torch.device('mps')\n\nI did some webscraping to download the images of the pokemon index as seen here: https://www.pokemon.com/us/pokedex. We collect the images as well as the first type for each of the 1010 pokemons.\n\ndf = pd.read_csv('data/pokemon_df.csv')\ndf['Ndex'] = df['Ndex'].apply(lambda x: int(x[1:]))\ndf\n\n\n\n\n\n\n\n\nUnnamed: 0\nNdex\nMS\nPokémon\nType\nType.1\n\n\n\n\n0\n0\n1\nNaN\nBulbasaur\nGrass\nPoison\n\n\n1\n1\n2\nNaN\nIvysaur\nGrass\nPoison\n\n\n2\n2\n3\nNaN\nVenusaur\nGrass\nPoison\n\n\n3\n3\n4\nNaN\nCharmander\nFire\nFire\n\n\n4\n4\n5\nNaN\nCharmeleon\nFire\nFire\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1165\n119\n0\nNaN\nOgerpon\nUnknown\nUnknown\n\n\n1166\n120\n0\nNaN\nOkidogi\nUnknown\nUnknown\n\n\n1167\n121\n0\nNaN\nMunkidori\nUnknown\nUnknown\n\n\n1168\n122\n0\nNaN\nFezandipiti\nUnknown\nUnknown\n\n\n1169\n123\n0\nNaN\nTerapagos\nUnknown\nUnknown\n\n\n\n\n1170 rows × 6 columns\n\n\n\nHere is the list of Pokemons. Interestingly sometimes there are two versions of the same pokemon such as different colors or shapes, but they have the same index numbering. Hence we select only the unique NDex pokemon id’s and the first variants type and image. Next we sort the pictures based on type into different subfolders to make the loading into the dataloaders function easier.\n\npath_images = Path('data/pictures/pokemon_1.png')\n# To create the folders of Pokemon Types\nfor type in df['Type'].unique():\n    os.mkdir(f'data/pictures/{type}')\n\n# Moving them in the correct folders\nfor i in range(1, len(df['Ndex'].unique())):\n    frame = df.loc[df['Ndex'] == i]\n    row = frame.iloc[0]\n    type = row['Type']\n    os.rename(f'data/pictures/pokemon_{i}.png', f'data/pictures/{type}/pokemon_{i}.png')\n\n\n# Building the datablock\nget_image_files(path='data/pictures/')\npath = Path('data/pictures/')\npokemons = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\n\n# now we need to tell our datablock where our items are\ndls = pokemons.dataloaders(path)\n\n\ndls.valid.show_batch(max_n=9, nrows=3)\n\n\n\n\nData Input Batch\n\n\n\n\n\n# Train and learning\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n4.255514\n3.037972\n0.841584\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n3.232000\n2.865299\n0.787129\n00:07\n\n\n1\n2.717485\n2.688650\n0.732673\n00:06\n\n\n2\n2.179033\n2.699625\n0.717822\n00:06\n\n\n3\n1.707126\n2.728021\n0.688119\n00:06\n\n\n4\n1.326017\n2.723592\n0.698020\n00:06\n\n\n5\n1.036368\n2.749372\n0.693069\n00:06\n\n\n6\n0.828428\n2.756829\n0.702970\n00:06\n\n\n7\n0.679754\n2.762048\n0.707921\n00:06\n\n\n\n\n\n\n# Exporting the weights so that we can put our model online on huggingface\nlearn.path = Path('.')\nlearn.export()\n\n\n# Let's see the big Matrix\n# |label: confusion-matrix\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe take a look at the confusion matrix, which plots the predicted labels vs the actuals. We can see that the types “Fire, Grass, and Water” appear to be the easiest to identify. To any pokemon player this makes sense, as these three types are differently colored such as “red, green, and blue”. As a last step we briefly look at the top losses of our classifier. Losses are the MSE (Mean Squared Error) a high loss indicates that our model did bad. There are further nuances to that such that it is especially bad if our model is wrong, but is very certain of the prediction. We can for example see a rock pokemon that was predicted to be a water pokemon, with a probability of 0.97\n\ninterp.plot_top_losses(5, nrows=1)\n\n\n\n\n\n\n\n\n\n\n\nThen again when looking at these images it seems tough to predict what type they are. Would you be able to? You can take a guess here: PokemonTypeClassifier"
  }
]